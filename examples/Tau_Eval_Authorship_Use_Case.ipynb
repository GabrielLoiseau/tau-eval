{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNA+nwV5z+nLls3MWSgkiLd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GabrielLoiseau/tau-eval/blob/main/examples/Tau_Eval_Authorship_Use_Case.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U tau-eval datasets huggingface_hub fsspec"
      ],
      "metadata": {
        "id": "5fU3TkI43PzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use Case: Authorship Obfuscation with Tau-Eval\n",
        "\n",
        "**Introduction** Authorship obfuscation aims to modify a piece of text to conceal the original author's writing style, thereby protecting their privacy or anonymizing the text for other purposes. This can involve techniques like paraphrasing, style transfer, or simplification.\n",
        "\n",
        "This notebook demonstrates how to use Tau-Eval's built-in models designed for authorship modification/obfuscation. We will also explore how to use Tau-Eval's utility metrics and visualization tools to assess the impact of these transformations on the text's content and quality.\n",
        "\n",
        "## Section 1: Setting up Environment and Models"
      ],
      "metadata": {
        "id": "ht2lUoZOt5k9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Only used if you evaluate api-based models\n",
        "os.environ[\"OPENROUTER_API_KEY\"] = \"your-api-key\""
      ],
      "metadata": {
        "id": "-3zbadmb3Qvr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tau_eval.models.authorship import KeepItSimple, Paraphraser, M2M100MT\n",
        "#from tau_eval.models.llm_api import LLMAuthorship\n",
        "\n",
        "p1 = KeepItSimple()\n",
        "p2 = Paraphraser()\n",
        "p3 = M2M100MT()\n",
        "# Uncomment if you are using an Openrouter API key\n",
        "#p4 = LLMAuthorship(\"google/gemini-flash-1.5-8b\")\n",
        "#p5 = LLMAuthorship(\"google/gemini-flash-1.5\")\n",
        "\n",
        "MODEL_LIST = [p1,p2,p3]"
      ],
      "metadata": {
        "id": "sKL6rH383SRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 2: Preparing Tasks and Metrics"
      ],
      "metadata": {
        "id": "5NjqumcTuzwi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tau_eval.tasks import IMDBAuthorshipClassification\n",
        "import tasknet as tn\n",
        "\n",
        "imdb = IMDBAuthorshipClassification(n_authors=10, max_rows=1000, max_rows_eval=1000)\n",
        "dynahate = tn.AutoTask('dynahate', max_rows=10000, max_rows_eval=1000)\n",
        "anli = tn.AutoTask('anli/a1')\n",
        "\n",
        "METRICS = [\"rouge\",\"meteor\",\"bertscore\"]\n",
        "TASKS = [imdb,dynahate,anli]"
      ],
      "metadata": {
        "id": "url_g8vg3Tb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 3: Running the Authorship Obfuscation Experiment"
      ],
      "metadata": {
        "id": "QlXql9A4u1FC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tau_eval import Experiment, ExperimentConfig\n",
        "\n",
        "config = ExperimentConfig(\"authorship-obfuscation\",\"answerdotai/ModernBERT-base\",True, False)\n",
        "\n",
        "e = Experiment(MODEL_LIST,METRICS,TASKS,config)\n",
        "\n",
        "e.run(output_dir=\"results-authorship.json\")"
      ],
      "metadata": {
        "id": "bVHGRr6l3UeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 4: Visualize results"
      ],
      "metadata": {
        "id": "n79BVA1hp9pq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tau_eval import Experiment\n",
        "\n",
        "e = Experiment.from_json(\"results-authorship.json\")"
      ],
      "metadata": {
        "id": "_jb4AAq8qLUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "e.summary().keys()"
      ],
      "metadata": {
        "id": "Z9nY7MPjtii3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tau_eval.visualization import plot_all_metrics_for_model_on_dataset\n",
        "\n",
        "plot_all_metrics_for_model_on_dataset(e.results, 'anli/plain_text_2', p1.name)"
      ],
      "metadata": {
        "id": "2WXEJbYKrE_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tau_eval.visualization import plot_metric_distribution\n",
        "\n",
        "plot_metric_distribution(e.results, 'rouge1')"
      ],
      "metadata": {
        "id": "pdXPiJSFr5Eq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tau_eval.visualization import plot_trade_off_metric\n",
        "\n",
        "plot_trade_off_metric(e.results, \"test_accuracy\", \"rouge1\", ['anli/plain_text_2'], [p.name for p in MODEL_LIST])"
      ],
      "metadata": {
        "id": "o84OZxHgsFvx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}